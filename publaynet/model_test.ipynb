{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    a test script for box-shape reconstruction\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import vis_utils_layout as vis_utils\n",
    "from data_layout import LayoutDataset, Tree\n",
    "import model_layout as model\n",
    "from random import shuffle\n",
    "\n",
    "sys.setrecursionlimit(5000) # this code uses recursion a lot for code simplicity\n",
    "\n",
    "# how many shapes to evaluate (the top-K in test.txt)\n",
    "num_recon = 50\n",
    "\n",
    "path = 'exp_vae_mag'\n",
    "cheakpoint = ''\n",
    "\n",
    "# load train config\n",
    "conf = torch.load(path + '/conf.pth')\n",
    "\n",
    "# load object category information\n",
    "Tree.load_category_info(conf.category)\n",
    "conf.device = 'cuda:1'\n",
    "\n",
    "# set up device\n",
    "device = torch.device(conf.device)\n",
    "print(f'Using device: {conf.device}')\n",
    "\n",
    "# check if eval results already exist. If so, delete it. \n",
    "out_dir = path + '/reconstructed_shapes'\n",
    "if os.path.exists(out_dir):\n",
    "    # response = input('result directory %s exists, overwrite? (y/n) ' % out_dir)\n",
    "    # if response != 'y':\n",
    "    #     sys.exit()\n",
    "    shutil.rmtree(out_dir)\n",
    "\n",
    "# create a new directory to store eval results\n",
    "os.mkdir(out_dir)\n",
    "\n",
    "# create models\n",
    "# we disable probabilistic because we do not need to jitter the decoded z during inference\n",
    "encoder = model.RecursiveEncoder(conf, variational=True, probabilistic=False)\n",
    "decoder = model.RecursiveDecoder(conf)\n",
    "\n",
    "# load the pretrained models\n",
    "print('Loading ckpt pretrained_encoder.pth')\n",
    "data_to_restore = torch.load('./' + path + '/ckpts/' + cheakpoint + 'net_encoder.pth')\n",
    "encoder.load_state_dict(data_to_restore, strict=True)\n",
    "print('DONE\\n')\n",
    "print('Loading ckpt pretrained_decoder.pth')\n",
    "data_to_restore = torch.load('./' + path + '/ckpts/' + cheakpoint + 'net_decoder.pth')\n",
    "decoder.load_state_dict(data_to_restore, strict=True)\n",
    "print('DONE\\n')\n",
    "\n",
    "# send to device\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# set models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# read test.txt\n",
    "with open('../data/magazine_real_1104_1W/train.txt', 'r') as fin:\n",
    "    data_list = [l.rstrip() for l in fin.readlines()]\n",
    "\n",
    "shuffle(data_list)\n",
    "\n",
    "# reconstruct shapes\n",
    "with torch.no_grad():\n",
    "    for i in range(num_recon):\n",
    "        print(f'Reconstructing {i}/{num_recon} ...')\n",
    "\n",
    "        # load the gt data as the input\n",
    "        obj = LayoutDataset.load_object('../data/magazine_real_1104_1W/'+data_list[i]+'.json')\n",
    "        obj.to(device)\n",
    "\n",
    "        # feed through the encoder to get a code z\n",
    "        # root_code = encoder.encode_structure(obj)\n",
    "        root_code_and_kld = encoder.encode_structure(obj)\n",
    "        root_code = root_code_and_kld[:, :conf.feature_size]\n",
    "\n",
    "        # infer through the decoder to get the reconstructed output\n",
    "        # set maximal tree depth to conf.max_tree_depth\n",
    "        obj_arr = decoder.decode_structure(z=root_code, max_depth=conf.max_tree_depth)\n",
    "        obj_arr.get_arrbox()\n",
    "\n",
    "        # output the hierarchy\n",
    "        with open(os.path.join(out_dir, 'data-%03d.txt'%i), 'w') as fout:\n",
    "            fout.write(data_list[i]+'\\n\\n')\n",
    "            fout.write(str(obj)+'\\n\\n')\n",
    "            fout.write(str(obj_arr)+'\\n\\n')\n",
    "\n",
    "        # output the assembled box-shape\n",
    "        vis_utils.draw_partnet_objects([obj, obj_arr], \\\n",
    "            object_names=['GT', 'PRED'], leafs_only=True, \\\n",
    "            sem_colors_filename='./part_colors_magazine.txt', figsize=(10, 6), \\\n",
    "            out_fn=os.path.join(out_dir, '%d.png'%i))\n",
    "        # vis_utils.draw_partnet_objects([obj_pred], object_names=['PRED'], figsize=(3, 5),\\\n",
    "        #         leafs_only=True, sem_colors_filename='./part_colors_magazine.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f903b2b60a8b91cd2748e4b89510df54c458a48099b7a4d252a18ecd2999490e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
