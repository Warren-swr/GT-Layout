{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "Loading ckpt pretrained_encoder.pth\n",
      "DONE\n",
      "\n",
      "Loading ckpt pretrained_decoder.pth\n",
      "DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import vis_utils_layout as vis_utils\n",
    "from data_layout import LayoutDataset, Tree\n",
    "import model_layout as model\n",
    "import tqdm\n",
    "\n",
    "sys.setrecursionlimit(5000) \n",
    "\n",
    "num_gen = 300\n",
    "num_recon = 300\n",
    "exp = 'publay-1W'\n",
    "category = 'publaynet'\n",
    "checkpoint = '212_'\n",
    "device = 'cuda:0'\n",
    "\n",
    "path = '/home/weiran/Projects/RvNN-Layout/GT-Layout/' + category + '/logs/' + exp\n",
    "data_path = '/home/weiran/Projects/RvNN-Layout/data/' + category + '-ours/' + exp\n",
    "\n",
    "# load train config\n",
    "conf = torch.load(path + '/conf.pth')\n",
    "\n",
    "# load object category information\n",
    "Tree.load_category_info(conf.category)\n",
    "\n",
    "# set up device\n",
    "print(f'Using device: {conf.device}')\n",
    "\n",
    "recon_dir = path + '/recon/'\n",
    "gen_dir = path + '/generation/'\n",
    "\n",
    "if os.path.exists(recon_dir):\n",
    "    shutil.rmtree(recon_dir)\n",
    "os.mkdir(recon_dir)\n",
    "\n",
    "if os.path.exists(gen_dir):\n",
    "    shutil.rmtree(gen_dir)\n",
    "os.mkdir(gen_dir)\n",
    "\n",
    "# create models\n",
    "# we disable probabilistic because we do not need to jitter the decoded z during inference\n",
    "encoder = model.RecursiveEncoder(conf, variational=True, probabilistic=False)\n",
    "decoder = model.RecursiveDecoder(conf)\n",
    "\n",
    "# load the pretrained models\n",
    "print('Loading ckpt pretrained_encoder.pth')\n",
    "data_to_restore = torch.load(path + '/ckpts/' + checkpoint + 'net_encoder.pth')\n",
    "encoder.load_state_dict(data_to_restore, strict=True)\n",
    "print('DONE\\n')\n",
    "print('Loading ckpt pretrained_decoder.pth')\n",
    "data_to_restore = torch.load(path + '/ckpts/' + checkpoint + 'net_decoder.pth')\n",
    "decoder.load_state_dict(data_to_restore, strict=True)\n",
    "print('DONE\\n')\n",
    "\n",
    "# send to device\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# set models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# read test.txt\n",
    "with open(data_path + '/train.txt', 'r') as fin:\n",
    "    data_list = [l.rstrip() for l in fin.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:56<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct shapes\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.tqdm(range(num_recon)):\n",
    "        # load the gt data as the input\n",
    "        obj = LayoutDataset.load_object(data_path + '/' + data_list[i] + '.json')\n",
    "        obj.to(device)\n",
    "\n",
    "        # feed through the encoder to get a code z\n",
    "        # root_code = encoder.encode_structure(obj)\n",
    "        root_code_and_kld = encoder.encode_structure(obj)\n",
    "        root_code = root_code_and_kld[:, :conf.feature_size]\n",
    "\n",
    "        # infer through the decoder to get the reconstructed output\n",
    "        # set maximal tree depth to conf.max_tree_depth\n",
    "        obj_arr = decoder.decode_structure(z=root_code, max_depth=conf.max_tree_depth)\n",
    "        obj_arr.get_arrbox()\n",
    "\n",
    "        # output the hierarchy\n",
    "        with open(os.path.join(recon_dir, data_list[i] + '_GT.txt'), 'w') as fout:\n",
    "            fout.write(str(obj)+'\\n\\n')\n",
    "            \n",
    "        with open(os.path.join(recon_dir, data_list[i] + '_PRED.txt'), 'w') as fout:\n",
    "            fout.write(str(obj_arr)+'\\n\\n')\n",
    "\n",
    "        # output the assembled box-shape\n",
    "        vis_utils.draw_partnet_objects([obj], \\\n",
    "            object_names=['GT'], leafs_only=True, \\\n",
    "            sem_colors_filename='./part_colors_magazine.txt', figsize=(5, 5), \\\n",
    "            out_fn=os.path.join(recon_dir, data_list[i] + '_GT.png'))\n",
    "        \n",
    "        vis_utils.draw_partnet_objects([obj], \\\n",
    "            object_names=['GT'], leafs_only=True, \\\n",
    "            sem_colors_filename='./part_colors_magazine.txt', figsize=(5, 5), \\\n",
    "            out_fn=os.path.join(recon_dir, data_list[i] + '_GT.svg'))\n",
    "        \n",
    "        vis_utils.draw_partnet_objects([obj_arr], \\\n",
    "            object_names=['PRED'], leafs_only=True, \\\n",
    "            sem_colors_filename='./part_colors_magazine.txt', figsize=(5, 5), \\\n",
    "            out_fn=os.path.join(recon_dir, data_list[i] + '_PRED.png'))\n",
    "\n",
    "        vis_utils.draw_partnet_objects([obj_arr], \\\n",
    "            object_names=['PRED'], leafs_only=True, \\\n",
    "            sem_colors_filename='./part_colors_magazine.txt', figsize=(5, 5), \\\n",
    "            out_fn=os.path.join(recon_dir, data_list[i] + '_PRED.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:58<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate shapes\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.tqdm(range(num_gen)):\n",
    "        # get a Gaussian noise\n",
    "        code = torch.randn(1, conf.feature_size).to(device)\n",
    "        \n",
    "        # infer through the model to get the generated hierarchy\n",
    "        # set maximal tree depth to conf.max_tree_depth\n",
    "        obj_arr = decoder.decode_structure(z=code, max_depth=conf.max_tree_depth)\n",
    "\n",
    "        obj_arr.get_arrbox()\n",
    "        \n",
    "        # output the hierarchy\n",
    "        with open(os.path.join(gen_dir, 'gen-%03d.txt'%i), 'w') as fout:\n",
    "            fout.write(str(obj_arr)+'\\n\\n')\n",
    "\n",
    "        # output the assembled box-shape\n",
    "        vis_utils.draw_partnet_objects([obj_arr],\\\n",
    "                object_names=['GENERATION'], \\\n",
    "                figsize=(5, 5), out_fn=os.path.join(gen_dir, 'gen-%03d.png'%i),\\\n",
    "                leafs_only=True,sem_colors_filename='./part_colors_magazine.txt')\n",
    "        \n",
    "        vis_utils.draw_partnet_objects([obj_arr], \\\n",
    "            object_names=['GENERATION'], leafs_only=True, \\\n",
    "            sem_colors_filename='./part_colors_magazine.txt', figsize=(5, 5), \\\n",
    "            out_fn=os.path.join(gen_dir, 'gen-%03d.svg'%i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
